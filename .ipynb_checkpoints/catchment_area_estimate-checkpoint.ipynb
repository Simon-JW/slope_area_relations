{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     44
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style()\n",
    "import numpy as np\n",
    "import operator\n",
    "import seaborn as sns; sns.set()\n",
    "from landlab import FieldError\n",
    "from landlab.utils import get_watershed_mask\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import gdal\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import *\n",
    "import os\n",
    "import math\n",
    "from osgeo import osr\n",
    "from fractions import Fraction\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "# import plotting tools\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib as mpl\n",
    "from pylab import show, figure\n",
    "from landlab.plot.imshow import imshow_grid \n",
    "\n",
    "# import necessary landlab components\n",
    "from landlab import RasterModelGrid, HexModelGrid\n",
    "from landlab.components import FlowAccumulator, LakeMapperBarnes, SinkFillerBarnes\n",
    "from landlab.components import(FlowDirectorD8, \n",
    "                               FlowDirectorDINF, \n",
    "                               FlowDirectorMFD, \n",
    "                               FlowDirectorSteepest)\n",
    "from landlab.components import DepressionFinderAndRouter\n",
    "# import landlab plotting functionality\n",
    "from landlab.plot.drainage_plot import drainage_plot\n",
    "from pylab import show, figure\n",
    "\n",
    "# create a plotting routine to make a 3d plot of our surface. \n",
    "def surf_plot(mg, surface='topographic__elevation', \n",
    "              title='Surface plot of topography', colormap = cm.gray):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot the surface.\n",
    "    Z = (mg.at_node[surface].reshape(mg.shape))#[y1:y2, x1:x2]\n",
    "    color = colormap((Z-Z.min())/(Z.max()-Z.min()))\n",
    "    surf = ax.plot_surface(mg.node_x.reshape(mg.shape),#[y1:y2, x1:x2]\n",
    "                           mg.node_y.reshape(mg.shape),#[y1:y2, x1:x2]\n",
    "                           Z,\n",
    "                           rstride=1, cstride=1,\n",
    "                           facecolors=color,\n",
    "                           linewidth=0.,\n",
    "                           antialiased=False)\n",
    "    ax.view_init(elev=35, azim=-120)\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Elevation')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     6,
     18,
     42,
     60,
     73,
     86,
     92,
     103,
     112,
     120
    ]
   },
   "outputs": [],
   "source": [
    "def rectangleWindow(m, n):\n",
    "    \"\"\"Takes a value for number of rows (m) and number of columns (n) such that\n",
    "       m and n are both positive real numbers and creates a rectangle of \n",
    "       boolian 'True' values.\"\"\"\n",
    "    rectangle = np.ones((m, n), dtype=bool) \n",
    "    return rectangle\n",
    "def number_of_values(Window):\n",
    "    \"\"\"This funciton takes the shape function as an input and returns a number \n",
    "        of values present in the specified shape. \n",
    "        \n",
    "        This can be different for a different window shape and to initialize\n",
    "        requires the specification of the function for the given window type and \n",
    "        parameter values required for that input function.\n",
    "        \n",
    "        To initialize this function for shape == rectangle type 'number_of_values(rectangleWindow(m,n)) \n",
    "        where m and n are any positive real number as per the rectangleWindow function.\"\"\"\n",
    "    denominator = sum(sum(Window > 0))\n",
    "    return denominator\n",
    "def slopeWindow(DEM_slope, x_cellsize, y_cellsize):\n",
    "    \"\"\"This function implements slope calculation using the same algorithm\n",
    "       as ARCGIS (Outlined on the page 'How Slope Works').\n",
    "       This particular example of the function is written such that it\n",
    "       will only work if called within the ndimage generic_filter (as the first input).\n",
    "       This is because the index arguments for a-e are given for the 1d array created\n",
    "       by the generic_filter function after extracting values from the 3,3 rectangle window.\n",
    "       NOTE: THIS FUNCTION ONLY WORKS WITH A 3x3 RECTANGLE WINDOW.\"\"\"\n",
    "    a = DEM_slope[0]; b = DEM_slope[1]; c = DEM_slope[2]\n",
    "    d = DEM_slope[3]; e = DEM_slope[4]; f = DEM_slope[5]\n",
    "    g = DEM_slope[6]; h = DEM_slope[7]; i = DEM_slope[8]\n",
    "    dzdx = ((c + (2*f) + i) - (a + (2*d) + g)) / (8 * x_cellsize)\n",
    "    dzdy = ((g + (2*h) + i) - (a + (2*b) + c)) / (8 * y_cellsize)\n",
    "    rise_run = np.sqrt(dzdx**2 + dzdy**2)\n",
    "    slope_degrees = np.arctan(rise_run) * (180/math.pi)\n",
    "    slope_percent = rise_run * 100\n",
    "    #Can also ask it to return slope_degrees but askinh for both causes it to throw and error.\n",
    "    return slope_percent\n",
    "\n",
    "# The 'extra_arguments' variable requires a value that represents r in the PCTL function defined above.\n",
    "# The reason it need to be assigned to a seperate variable is that the generic_filter function only allows the\n",
    "# input function (PCTL in this case) to take one argument (S1). Then, if the input function normally \n",
    "# takes more than one argument the 'extra_arguments' variable needs to be defined as a tuple \n",
    "# (hence (3,) instead of (3)).\n",
    "def slopeWindowDegrees(DEM, x_cellsize, y_cellsize):\n",
    "    \"\"\"This function implements slope calculation using the same algorithm\n",
    "       as ARCGIS (Outlined on the page 'How Slope Works').\n",
    "       This particular example of the function is written such that it\n",
    "       will only work if called within the ndimage generic_filter (as the first input).\n",
    "       This is because the index arguments for a-e are given for the 1d array created\n",
    "       by the generic_filter function after extracting values from the 3,3 rectangle window.\n",
    "       NOTE: THIS FUNCTION ONLY WORKS WITH A 3x3 RECTANGLE WINDOW.\"\"\"\n",
    "    a = DEM[0]; b = DEM[1]; c = DEM[2]\n",
    "    d = DEM[3]; e = DEM[4]; f = DEM[5]\n",
    "    g = DEM[6]; h = DEM[7]; i = DEM[8]\n",
    "    dzdx = ((c + (2*f) + i) - (a + (2*d) + g)) / (8 * x_cellsize)\n",
    "    dzdy = ((g + (2*h) + i) - (a + (2*b) + c)) / (8 * y_cellsize)\n",
    "    rise_run = np.sqrt(dzdx**2 + dzdy**2)\n",
    "    slope_degrees = np.arctan(rise_run) * (180/math.pi)\n",
    "    slope_percent = rise_run * 100\n",
    "    #Can also ask it to return slope_degrees but asking for both causes it to throw and error.\n",
    "    return slope_degrees\n",
    "def planCurvature(DEM, cellsize):\n",
    "    \"\"\"This process is taken from Change (2014, Introduction to Geographic Information\n",
    "    systems, Page 284).\"\"\"\n",
    "    Z1 = DEM[0]; Z2 = DEM[1]; Z3 = DEM[2]\n",
    "    Z4 = DEM[3]; Z0 = DEM[4]; Z5 = DEM[5]\n",
    "    Z6 = DEM[6]; Z7 = DEM[7]; Z8 = DEM[8]\n",
    "    D = (((Z4 + Z5)/2) - Z0) / cellsize**2\n",
    "    E = (((Z2 + Z7)/2) - Z0) / cellsize**2\n",
    "    F = (Z3 - Z1 + Z6 - Z8)/ (4 * cellsize**2)\n",
    "    G = (Z5 - Z4) / (2 * cellsize)\n",
    "    H = (Z2 - Z7) / (2 * cellsize)\n",
    "    plan_curvature = (2 * (D*(H**2) + E*(G**2) - (F*G*H))) / (G**2 + H**2)\n",
    "    return plan_curvature\n",
    "def profileCurvature(DEM, cellsize):\n",
    "    \"\"\"This process is taken from Change (2014, Introduction to Geographic Information\n",
    "       systems, Page 284).\"\"\"\n",
    "    Z1 = DEM[0]; Z2 = DEM[1]; Z3 = DEM[2]\n",
    "    Z4 = DEM[3]; Z0 = DEM[4]; Z5 = DEM[5]\n",
    "    Z6 = DEM[6]; Z7 = DEM[7]; Z8 = DEM[8]\n",
    "    D = (((Z4 + Z5)/2) - Z0) / cellsize**2\n",
    "    E = (((Z2 + Z7)/2) - Z0) / cellsize**2\n",
    "    F = (Z3 - Z1 + Z6 - Z8)/ (4 * cellsize**2)\n",
    "    G = (Z5 - Z4) / (2 * cellsize)\n",
    "    H = (Z2 - Z7) / (2 * cellsize)\n",
    "    profile_curvature = (-2 * (D*(G**2) + E*(H**2) + (F*G*H))) / (G**2 + H**2)\n",
    "    return profile_curvature\n",
    "def circleWindow(radius):\n",
    "    \"\"\"Takes a value for radius (r where r is any positive real number) and creates \n",
    "       a circular window using that radius.\"\"\"\n",
    "    y, x = np.ogrid[-radius: radius + 1, -radius: radius + 1]\n",
    "    circle = x**2 + y**2 <= radius**2\n",
    "    return circle\n",
    "def find_median_value(Window):\n",
    "    \"\"\"This function takes the shape function and returns the median value \n",
    "        for all valid values (values that fall in the circle) arranged into a \n",
    "        1d array. The function also takes the number_of_values function as an input.\n",
    "        To execute this function type 'find_median_value(shape(r)) where r is any integer.\n",
    "        #Note: using median like this only gives the correct value for circles with odd \n",
    "        radius values.\"\"\"\n",
    "    no_values = number_of_values(Window)\n",
    "    value_range = np.arange(0, no_values + 1)\n",
    "    central_value = int(np.median(value_range))\n",
    "    return central_value\n",
    "def difference_from_mean_elevation(elev):\n",
    "    \"\"\"This function only works as an inside function to generic_filter function below. This\n",
    "       is because generic_filter will take a 2d array and reshape it into a 1d array. Without this \n",
    "       step the 'central_value' variable will be outside of the array dimensions. \n",
    "       x = input DEM and r = radius of search window \"\"\"\n",
    "    centroid = elev[central_value]                        \n",
    "    mean = np.nanmean(elev)#Count number of values greater than centroid value\n",
    "    diff = centroid - mean\n",
    "    return diff\n",
    "def PCTL(x):\n",
    "    \"\"\"This function only works as an inside function to generic_filter function below. This\n",
    "       is because generic_filter will take a 2d array and reshape it into a 1d array. Without this \n",
    "       step the 'central_value' variable will be outside of the array dimensions. \n",
    "       x = input DEM and r = radius of search window \"\"\"\n",
    "    centroid = x[central_value]                        \n",
    "    y = np.sum(x < centroid)/num_values#Count number of values greater than centroid value\n",
    "    return y\n",
    "def catchmentDicts(area_grid, gn, gh_nodes):\n",
    "    \"\"\"Creates a dictionary of node ID:catcment area values.\"\"\"\n",
    "    area_dict = {}\n",
    "    keys = gh_nodes\n",
    "    for i in keys:\n",
    "        area_grid_copy = np.copy(area_grid)\n",
    "        corresponding_grid_cell = np.isin(gn, i).astype(bool)\n",
    "        area_grid_copy[~corresponding_grid_cell] = np.nan\n",
    "        area = np.unique(area_grid_copy[~np.isnan(area_grid_copy)])[0]\n",
    "        area_dict[i] = area\n",
    "    return area_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_DEM_resolution = 1\n",
    "location = (r'C:\\PhD\\manuscript\\flow_routing_algorithms\\data')\n",
    "os.chdir(location)\n",
    "input_geotiff = gdal.Open('fann_2013_5m.tif')\n",
    "ig = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())\n",
    "#input_DEM = scipy.ndimage.zoom(x, input_DEM_resolution / initial_resolution, order = 1)\n",
    "input_DEM = ig\n",
    "gully_head_layer = gdal.Open('core_nodes_5m.tif')\n",
    "gh = np.array(gully_head_layer.GetRasterBand(1).ReadAsArray()).astype('uint8')\n",
    "# This is only required because ArcGIS produced the original grid with 1 as background and 0 as points.\n",
    "#gully_heads = (gh - 1)**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = gdal.Open('grid_nodes_5m.tif')\n",
    "grid_nodes = np.array(nodes.GetRasterBand(1).ReadAsArray()).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grid_nodes, cmap=\"terrain\");\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate all gully head nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nodes = np.multiply(gh, grid_nodes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create array of only gully head nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_array = np.unique(find_nodes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn gully head node array into a list and remove the value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_list = gh_array.tolist();\n",
    "gh_list.remove(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gh_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work through list finding index positions of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256216\n",
      "321408\n",
      "336660\n",
      "364791\n",
      "366791\n",
      "368953\n",
      "373679\n",
      "375796\n",
      "380143\n",
      "382196\n",
      "384197\n",
      "384567\n",
      "395431\n",
      "399564\n",
      "408102\n",
      "410426\n",
      "416818\n",
      "421077\n",
      "427705\n",
      "430024\n",
      "432372\n",
      "436749\n",
      "438573\n",
      "438650\n",
      "443093\n",
      "449358\n",
      "453814\n",
      "454134\n",
      "458401\n",
      "458463\n",
      "460402\n",
      "460504\n",
      "469205\n",
      "475549\n",
      "477847\n",
      "479890\n",
      "480099\n",
      "482451\n",
      "486811\n",
      "492959\n",
      "493021\n",
      "495289\n",
      "499872\n",
      "510661\n",
      "523327\n",
      "523583\n",
      "525498\n",
      "536288\n",
      "536849\n",
      "540910\n",
      "551338\n",
      "551925\n",
      "554252\n",
      "564491\n",
      "566920\n",
      "569092\n",
      "571268\n",
      "578155\n",
      "582527\n",
      "583889\n",
      "584068\n",
      "584157\n",
      "592907\n",
      "595448\n",
      "597200\n",
      "599223\n",
      "599442\n",
      "601345\n",
      "603798\n",
      "608152\n",
      "610326\n",
      "615023\n",
      "616730\n",
      "616831\n",
      "625476\n",
      "636145\n",
      "636824\n",
      "640560\n",
      "641255\n",
      "642818\n",
      "649953\n",
      "651629\n",
      "653804\n",
      "653972\n",
      "664537\n",
      "664672\n",
      "670964\n",
      "671393\n",
      "672951\n",
      "673576\n",
      "676052\n",
      "677585\n",
      "680085\n",
      "682279\n",
      "690472\n",
      "701573\n",
      "703736\n",
      "707776\n",
      "708305\n",
      "710124\n",
      "712299\n",
      "716795\n",
      "723282\n",
      "732340\n",
      "740833\n",
      "742740\n",
      "743220\n",
      "744713\n",
      "744758\n",
      "746890\n",
      "746925\n",
      "747348\n",
      "751850\n",
      "753549\n",
      "756076\n",
      "757900\n",
      "764436\n",
      "764536\n",
      "767022\n",
      "771413\n",
      "773477\n",
      "784092\n",
      "790746\n",
      "791080\n",
      "792616\n",
      "792731\n",
      "793009\n",
      "793011\n",
      "793169\n",
      "795428\n",
      "801194\n",
      "806233\n",
      "810019\n",
      "810542\n",
      "814454\n",
      "814893\n",
      "816652\n",
      "816788\n",
      "817041\n",
      "818960\n",
      "819107\n",
      "820842\n",
      "822968\n",
      "825484\n",
      "825628\n",
      "836393\n",
      "838400\n",
      "842929\n",
      "846893\n",
      "849562\n",
      "851449\n",
      "851548\n",
      "856029\n",
      "860047\n",
      "860547\n",
      "864579\n",
      "871181\n",
      "873448\n",
      "873456\n",
      "877821\n",
      "880098\n",
      "886645\n",
      "888656\n",
      "899532\n",
      "901868\n",
      "905771\n",
      "908130\n",
      "910138\n",
      "910302\n",
      "914648\n",
      "927368\n",
      "929552\n",
      "929964\n",
      "938028\n",
      "956187\n",
      "957912\n",
      "962717\n",
      "963090\n",
      "964728\n",
      "967733\n",
      "968785\n",
      "970761\n",
      "973487\n",
      "974253\n",
      "977285\n",
      "978511\n",
      "984381\n",
      "984420\n",
      "990276\n",
      "991129\n",
      "992295\n",
      "996645\n",
      "997982\n",
      "998984\n",
      "999449\n",
      "1004094\n",
      "1006379\n",
      "1008203\n",
      "1010627\n",
      "1012552\n",
      "1014018\n",
      "1014894\n",
      "1019342\n",
      "1019767\n",
      "1026454\n",
      "1027221\n",
      "1027874\n",
      "1030233\n",
      "1031615\n",
      "1032435\n",
      "1033906\n",
      "1039072\n",
      "1049329\n",
      "1050199\n",
      "1054563\n",
      "1060563\n",
      "1068785\n",
      "1072542\n",
      "1075666\n",
      "1084309\n",
      "1084432\n",
      "1085034\n",
      "1087831\n",
      "1088784\n",
      "1098172\n",
      "1103049\n",
      "1109886\n",
      "1112064\n",
      "1116690\n",
      "1117742\n",
      "1118869\n",
      "1123405\n",
      "1124806\n",
      "1126373\n",
      "1127678\n",
      "1130344\n",
      "1131482\n",
      "1133650\n",
      "1134806\n",
      "1137081\n",
      "1138760\n",
      "1141350\n",
      "1147874\n",
      "1147960\n",
      "1151687\n",
      "1153100\n",
      "1159180\n",
      "1169210\n",
      "1169500\n",
      "1171679\n",
      "1173773\n",
      "1183009\n",
      "1183010\n",
      "1187028\n",
      "1189203\n",
      "1189533\n",
      "1190040\n",
      "1191174\n",
      "1193463\n",
      "1201769\n",
      "1208223\n",
      "1208346\n",
      "1208629\n",
      "1211457\n",
      "1215223\n",
      "1215299\n",
      "1219478\n",
      "1223597\n",
      "1223835\n",
      "1243102\n",
      "1243150\n",
      "1256951\n",
      "1269257\n",
      "1271433\n",
      "1288762\n",
      "1290761\n",
      "1297347\n",
      "1308336\n",
      "1316879\n",
      "1316924\n",
      "1324486\n",
      "1325699\n",
      "1339231\n",
      "1339549\n",
      "1345472\n",
      "1350417\n",
      "1353852\n",
      "1354750\n",
      "1356917\n",
      "1358565\n",
      "1358725\n",
      "1358730\n",
      "1361235\n",
      "1361247\n",
      "1362444\n",
      "1365254\n",
      "1366185\n",
      "1384305\n",
      "1385085\n",
      "1387266\n",
      "1388653\n",
      "1388821\n",
      "1393599\n",
      "1395359\n",
      "1400265\n",
      "1403693\n",
      "1405869\n",
      "1408977\n",
      "1412908\n",
      "1413946\n",
      "1417237\n",
      "1424751\n",
      "1429473\n",
      "1431659\n",
      "1440041\n",
      "1449796\n",
      "1462548\n",
      "1465014\n",
      "1465015\n",
      "1469329\n",
      "1477210\n",
      "1478151\n",
      "1480252\n",
      "1486232\n",
      "1490201\n",
      "1506423\n",
      "1508165\n",
      "1516291\n",
      "1523545\n",
      "1529506\n",
      "1532423\n",
      "1540578\n",
      "1547861\n",
      "1548913\n",
      "1550038\n",
      "1551991\n",
      "1554375\n",
      "1558535\n",
      "1563588\n",
      "1567130\n",
      "1567923\n",
      "1575813\n",
      "1578045\n",
      "1580475\n",
      "1606302\n",
      "1608175\n",
      "1608181\n",
      "1608476\n",
      "1610172\n",
      "1612347\n",
      "1621241\n",
      "1621767\n",
      "1633684\n",
      "1640586\n",
      "1650234\n",
      "1652796\n",
      "1656064\n",
      "1656151\n",
      "1657142\n",
      "1658638\n",
      "1658969\n",
      "1661953\n",
      "1665561\n",
      "1671277\n",
      "1685852\n",
      "1687034\n",
      "1688692\n",
      "1695226\n",
      "1697818\n",
      "1708071\n",
      "1708117\n",
      "1710115\n",
      "1721087\n",
      "1721556\n",
      "1722937\n",
      "1734293\n",
      "1739163\n",
      "1739294\n",
      "1739681\n",
      "1741422\n",
      "1741836\n",
      "1742883\n",
      "1743932\n",
      "1753713\n",
      "1755751\n",
      "1775780\n",
      "1775988\n",
      "1780926\n",
      "1802355\n",
      "1803304\n",
      "1808067\n",
      "1816668\n",
      "1867058\n",
      "1883738\n",
      "1889020\n",
      "1889192\n",
      "1895722\n",
      "1897182\n",
      "1899337\n",
      "1901852\n",
      "1905887\n",
      "1910704\n",
      "1915134\n",
      "1919547\n",
      "1923586\n",
      "1927933\n",
      "1928345\n",
      "1932598\n",
      "1936627\n",
      "1936868\n",
      "1940649\n",
      "1941219\n",
      "1945322\n",
      "1945716\n",
      "1947630\n",
      "1947906\n",
      "1960943\n",
      "1965473\n",
      "1997672\n",
      "2004108\n",
      "2008049\n",
      "2008456\n",
      "2010518\n",
      "2010519\n",
      "2014877\n",
      "2019622\n",
      "2021596\n",
      "2021795\n",
      "2025608\n",
      "2027607\n",
      "2027784\n",
      "2029770\n",
      "2032839\n",
      "2040642\n",
      "2054259\n",
      "2054271\n",
      "2078429\n",
      "2079736\n",
      "2079737\n",
      "2086281\n",
      "2095813\n",
      "2101474\n",
      "2104517\n",
      "2106092\n",
      "2106696\n",
      "2119620\n",
      "2121867\n",
      "2130346\n",
      "2136460\n",
      "2153969\n",
      "2171101\n",
      "2175625\n",
      "2177719\n",
      "2184668\n",
      "2190738\n",
      "2197777\n",
      "2199281\n",
      "2201688\n",
      "2201707\n",
      "2208033\n",
      "2212468\n",
      "2249298\n",
      "2262631\n",
      "2284633\n",
      "2297653\n",
      "2314830\n",
      "2360598\n",
      "2375727\n",
      "2377903\n",
      "2395404\n",
      "2397499\n",
      "2399673\n",
      "2399674\n",
      "2408062\n",
      "2427614\n",
      "2468910\n",
      "2477512\n",
      "2481891\n",
      "2495018\n",
      "2510461\n",
      "2566705\n",
      "2631938\n",
      "2664641\n",
      "2701571\n"
     ]
    }
   ],
   "source": [
    "catchment_area_dict = {}\n",
    "catchment_area_node_list = []\n",
    "distance_from_node = 2\n",
    "contributing_fraction = 0.9\n",
    "\n",
    "for i in gh_list:\n",
    "    print(i)\n",
    "    current_node = i\n",
    "    result = np.where(grid_nodes == current_node)\n",
    "    #################################################################################################\n",
    "    # Find the index position (in the whole DEM) that corresponds to the current gully head point in the list.\n",
    "    row_index = result[0][0];\n",
    "    col_index = result[1][0];\n",
    "    #################################################################################################\n",
    "    # Set a distance from the node to define the size of the subset taken (size of subset will be twice plus 1)\n",
    "    \n",
    "    #################################################################################################\n",
    "    # Create a subset based on above. Plus 1 to bottom abnd right so that the currenmmt gully ead node is always the \n",
    "    # centraL grid node of the subset.\n",
    "    subset_row_top = int(row_index - distance_from_node)\n",
    "    subset_row_bot = int(row_index + distance_from_node) + 1\n",
    "    subset_col_left = int(col_index - distance_from_node)\n",
    "    subset_col_right = int(col_index + distance_from_node) + 1\n",
    "    #################################################################################################\n",
    "    # Restrict the size of the subset in cases where it is on the edge of a DEM.\n",
    "    subset_row_top_adjusted = max(subset_row_top, 0);\n",
    "    subset_row_bot_adjusted = min(subset_row_bot, input_DEM.shape[0]);\n",
    "    subset_col_left_adjusted = max(subset_col_left, 0);\n",
    "    subset_col_right_adjusted = min(subset_col_right, input_DEM.shape[1]);\n",
    "    #################################################################################################\n",
    "    # Find the offset required by restricting the size of the subset around DEM edges.\n",
    "    # This offset is needed to find the new location of the current gully head grid cell (no longer center of the subset).\n",
    "    offset_row_top = int(np.sqrt((subset_row_top - subset_row_top_adjusted)**2)) * -1;\n",
    "    offset_row_bot = int(np.sqrt((subset_row_bot - subset_row_bot_adjusted)**2));\n",
    "    offset_col_left = int(np.sqrt((subset_col_left - subset_col_left_adjusted)**2)) * -1;\n",
    "    offset_col_right = int(np.sqrt((subset_col_right - subset_col_right_adjusted)**2));\n",
    "    #################################################################################################\n",
    "    # Create subset around the current gully head grid node. \n",
    "    dem_subset_copy = np.copy(input_DEM);\n",
    "    dem_subset = dem_subset_copy[subset_row_top_adjusted:subset_row_bot_adjusted, \n",
    "                                 subset_col_left_adjusted:subset_col_right_adjusted]\n",
    "    #################################################################################################\n",
    "    # Find the latitude and longitude index positions of the gully head node in the subset DEM.\n",
    "    node_lat = distance_from_node + offset_row_top\n",
    "    node_lon = distance_from_node + offset_col_left\n",
    "    #################################################################################################  \n",
    "    # Run M8 for the subset DEM.\n",
    "    flow_acc_surf_sub = np.copy(dem_subset).astype('float64');\n",
    "    \n",
    "    rows_sub = flow_acc_surf_sub.shape[0];\n",
    "    cols_sub = flow_acc_surf_sub.shape[1];\n",
    "    mg1 = RasterModelGrid((rows_sub,cols_sub), 1);\n",
    "    z1 = mg1.add_field('topographic__elevation', flow_acc_surf_sub, at = 'node');\n",
    "    \n",
    "    sfb = SinkFillerBarnes(mg1, method = 'Steepest', ignore_overfill = True);\n",
    "    sfb.run_one_step();\n",
    "    fa = FlowAccumulator(mg1,\n",
    "                        surface = 'topographic__elevation',\n",
    "                        flow_director = 'FlowDirectorMFD',\n",
    "                        diagonals = True);\n",
    "    \n",
    "    fa.run_one_step()\n",
    "    fd = FlowDirectorMFD(mg1, 'topographic__elevation', diagonals = True);\n",
    "    fd.run_one_step()\n",
    "    #################################################################################################\n",
    "    # Extract required grid properties\n",
    "    da = np.array(mg1.at_node['drainage_area'].round(4)); # Drainage area.\n",
    "    frn = mg1.at_node['flow__receiver_node'];# Flow receiver nodes.\n",
    "    drainage_area = da.reshape(mg1.shape);\n",
    "    frp = np.array(mg1.at_node['flow__receiver_proportions']);# Flow receiver proportions\n",
    "    flow_rec_surf_rows = cols_sub * rows_sub;\n",
    "    flow_rec_surf = frp.reshape(flow_rec_surf_rows,8);\n",
    "    all_receiver_proportions = np.copy(frp);\n",
    "    grid_nodes_sub = np.array(mg1.nodes.reshape(mg1.shape));\n",
    "    #################################################################################################\n",
    "    central_node = grid_nodes_sub[node_lat, node_lon]\n",
    "    # Specific the size of the area to be checked. This represents a physical distance from the \n",
    "    # outlet but has no unit of measure. Its maximum size is the size of the 'distance_from_node' variable.\n",
    "    \n",
    "    # This value is used to initialise the search.\n",
    "    catchment_outlet_id = central_node\n",
    "    \n",
    "    # Initate an outer loop that iterates through every distance interval from the outlet. Each iteration checks whether \n",
    "    # an area equal to the 'contributing_fraction' variable below is being directed in only one direction (converging).\n",
    "    # Otherwise it moves to the nect grid cell downslope in the direction of steepest slope.\n",
    "    \n",
    "    # Create a grid of node value sfor the subset DEM.\n",
    "    node_location = mg1.nodes.reshape(da.shape);\n",
    "    for j in range(0, distance_from_node):\n",
    "        # Begin at the point (node) digitized as the intersection between the central flow line and the gully head.\n",
    "        if j == 0:\n",
    "            candidate_gridcell = catchment_outlet_id;\n",
    "        else:\n",
    "            candidate_gridcell = next_cell_downstream;\n",
    "        # Get all receiver nodes of the current node.\n",
    "        grid_cell_receiver_nodes = frp[candidate_gridcell,:];\n",
    "        # Check if there is a node that receiving >= 'contributing_fraction' from the current node.\n",
    "        if np.amax(grid_cell_receiver_nodes) < contributing_fraction:\n",
    "            # Check if this is the last possible grid cell in the subset that could meet the criteria. If so, then there\n",
    "            # is no suitable grid cell (node).\n",
    "            if j == distance_from_node - 1:\n",
    "                catchment_area_dict[i] = 'No grid cell found'\n",
    "            else:\n",
    "                # Otherwise, find the next downslope grid cell receiving the highest proportion of flow and check that \n",
    "                # in the next iteration.\n",
    "                index_next_cell_downstream = np.where(grid_cell_receiver_nodes == np.amax(grid_cell_receiver_nodes))[0][0];\n",
    "                next_cell_downstream = frn[candidate_gridcell, index_next_cell_downstream];\n",
    "        else:\n",
    "            # Find the position of the gridcell (node) that meets the criteria both in the subset and in the whole DEM\n",
    "            # and record the node ID.\n",
    "            final_node_index_lat =  np.where(grid_nodes_sub == candidate_gridcell)[0][0]\n",
    "            final_node_index_lon =  np.where(grid_nodes_sub == candidate_gridcell)[1][0]\n",
    "            # Find the offest between the index position of the node the loop ends on, and the index position of\n",
    "            # the node that it started on. \n",
    "            final_lat_offset = final_node_index_lat - node_lat\n",
    "            final_lon_offset = final_node_index_lon - node_lon\n",
    "            # Then apply this offest to the index position of the starting node with respect top the whole DEM to find the \n",
    "            # node ID of the grid cell that met the criteria above.\n",
    "            final_row_index = row_index + final_lat_offset\n",
    "            final_col_index = col_index + final_lon_offset\n",
    "            node_of_area_record = grid_nodes[final_row_index, final_col_index]\n",
    "            catchment_area_dict[i] = node_of_area_record\n",
    "            catchment_area_node_list.append(node_of_area_record)\n",
    "            break\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 484\n"
     ]
    }
   ],
   "source": [
    "print(len(gh_list), len(catchment_area_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_mapping.to_csv(r'C:/PhD/junk/node_map.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_ids = np.isin(grid_nodes,catchment_area_node_list).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_geotiff = gdal.Open('fann_D4_5m.tif')\n",
    "D4 = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "input_geotiff = gdal.Open('fann_D8_5m.tif')\n",
    "D8 = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "input_geotiff = gdal.Open('fann_Dinf_5m.tif')\n",
    "Dinf = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "input_geotiff = gdal.Open('fann_M4_5m.tif')\n",
    "M4 = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "input_geotiff = gdal.Open('fann_M8_5m.tif')\n",
    "M8 = np.array(input_geotiff.GetRasterBand(1).ReadAsArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "D4_dict = catchmentDicts(D4, grid_nodes, catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "D8_dict = catchmentDicts(D8, grid_nodes, catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dinf_dict = catchmentDicts(Dinf, grid_nodes, catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "M4_dict = catchmentDicts(M4, grid_nodes, catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "M8_dict = catchmentDicts(M8, grid_nodes, catchment_area_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [D4_dict, D8_dict, Dinf_dict, M4_dict, M8_dict]\n",
    "d = {}\n",
    "for k in D4_dict.keys():\n",
    "    d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas = pd.DataFrame.from_dict(d, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas.rename(columns={0: 'D4', 1: 'D8', 2: 'Dinf', 3: 'M4', 4: 'M8'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D4</th>\n",
       "      <th>D8</th>\n",
       "      <th>Dinf</th>\n",
       "      <th>M4</th>\n",
       "      <th>M8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256215</th>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.442224</td>\n",
       "      <td>0.484330</td>\n",
       "      <td>0.253766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321407</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.905444</td>\n",
       "      <td>1.309828</td>\n",
       "      <td>0.717851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338834</th>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.649283</td>\n",
       "      <td>0.661906</td>\n",
       "      <td>0.508864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366965</th>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.769093</td>\n",
       "      <td>0.658916</td>\n",
       "      <td>0.503829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368965</th>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.736412</td>\n",
       "      <td>0.710110</td>\n",
       "      <td>0.604624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            D4      D8      Dinf        M4        M8\n",
       "256215  0.5825  0.2950  0.442224  0.484330  0.253766\n",
       "321407  0.6875  0.3250  0.905444  1.309828  0.717851\n",
       "338834  0.7350  0.6725  0.649283  0.661906  0.508864\n",
       "366965  0.8775  0.7725  0.769093  0.658916  0.503829\n",
       "368965  0.7125  0.8500  0.736412  0.710110  0.604624"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catchment_areas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_column = np.array(catchment_areas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas['node_id'] = node_id_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas.to_csv(r'C:/PhD/junk/catchment_areas_5m.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_5m_divergent = catchment_areas_5m_divergent.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas_1m_convergent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_areas_1m_divergent['Shape'] = 'Divergent'\n",
    "catchment_areas_1m_convergent['Shape'] = 'Convergent'\n",
    "catchment_areas_2m_divergent['Shape'] = 'Divergent'\n",
    "catchment_areas_2m_convergent['Shape'] = 'Convergent'\n",
    "catchment_areas_3m_divergent['Shape'] = 'Divergent'\n",
    "catchment_areas_3m_convergent['Shape'] = 'Convergent'\n",
    "catchment_areas_4m_divergent['Shape'] = 'Divergent'\n",
    "catchment_areas_4m_convergent['Shape'] = 'Convergent'\n",
    "catchment_areas_5m_divergent['Shape'] = 'Divergent'\n",
    "catchment_areas_5m_convergent['Shape'] = 'Convergent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_data = pd.concat([catchment_areas_1m_divergent,catchment_areas_2m_convergent,\n",
    "                      catchment_areas_2m_divergent,catchment_areas_2m_convergent,\n",
    "                      catchment_areas_3m_divergent,catchment_areas_3m_convergent,\n",
    "                      catchment_areas_4m_divergent,catchment_areas_4m_convergent,\n",
    "                      catchment_areas_5m_divergent,catchment_areas_5m_convergent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = area_data[['D4', 'Shape']]\n",
    "b = area_data[['D8', 'Shape']]\n",
    "c = area_data[['Dinf', 'Shape']]\n",
    "d = area_data[['M4', 'Shape']]\n",
    "e = area_data[['M8', 'Shape']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Method'] = 'D4'\n",
    "b['Method'] = 'D8'\n",
    "c['Method'] = 'Dinf'\n",
    "d['Method'] = 'M4'\n",
    "e['Method'] = 'M8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = a.rename(columns={'D4':'Area'})\n",
    "B = b.rename(columns={'D8':'Area'})\n",
    "C = c.rename(columns={'Dinf':'Area'})\n",
    "D = d.rename(columns={'M4':'Area'})\n",
    "E = e.rename(columns={'M8':'Area'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_data = pd.concat([A,B,C,D,E])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_data_reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = sns.distplot( A[\"Area\"] , color=\"skyblue\")\n",
    "plot = sns.distplot( B[\"Area\"] , color=\"olive\")\n",
    "plot = sns.distplot( C[\"Area\"] , color=\"gold\")\n",
    "plot = sns.distplot( D[\"Area\"] , color=\"teal\")\n",
    "plot.set_xlim(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot miles per gallon against horsepower with other semantics\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "g = sns.boxplot(x=\"Method\", y=\"Area\", palette=\"vlag\", hue = 'Shape', data=area_data)\n",
    "\n",
    "ax.set_ylabel('Catchment area (ha)', fontsize = 15)\n",
    "ax.set_xlabel('Routing algorithm', fontsize = 15)\n",
    "ax.set_ylim(-0.1, 4)\n",
    "#plt.title('Partitioning behaviour between adjacent gully heads', fontsize = 20)\n",
    "\n",
    "hatches = [\"\", \"/\", \"\",  \"/\", \"\",  \"/\", \"\",  \"/\", \"\", \"/\"]\n",
    "for hatch, patch in zip(hatches, g.artists):\n",
    "    patch.set_hatch(hatch)\n",
    "    \n",
    "hatches = [\"\", \"/\"]\n",
    "\n",
    "# Loop over the bars\n",
    "for i,thisbar in enumerate(g.patches):\n",
    "    # Set a different hatch for each bar\n",
    "    thisbar.set_hatch(hatches[i])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title = 'Flow above gully',fontsize='15')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style = \"ticks\")\n",
    "colors = [\"xkcd:very dark blue\", \"xkcd:mauve\"]\n",
    "\n",
    "def plot_unity(xdata, ydata, **kwargs):\n",
    "    mn = min(xdata.min(), ydata.min())\n",
    "    mx = max(xdata.max(), ydata.max())\n",
    "    points = np.linspace(mn, mx, 100)\n",
    "    plt.gca().plot(points, points, color = 'xkcd:merlot', marker=None,\n",
    "            linestyle='--', linewidth=1.0)\n",
    "\n",
    "g = sns.pairplot(area_data, palette = colors, hue = 'Shape', markers=['x', 'o'])\n",
    "\n",
    "sns.plotting_context()\n",
    "g.map_offdiag(plot_unity)\n",
    "\n",
    "g.set(ylim=(-0.5,6))\n",
    "g.set(xlim=(-0.5,6))\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    m = ax.get_ylabel()\n",
    "    ax.set_xlabel(l, fontsize=15)\n",
    "    ax.set_ylabel(m, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "data = area_data\n",
    "g0 = sns.scatterplot(x=\"M8\", y=\"Dinf\", marker = 'x', edgecolor= 'xkcd:royal blue', legend = False, \n",
    "                     linewidth = 1,data=data, hue = 'Shape')\n",
    "g1 = sns.scatterplot(x=\"M8\", y=\"D8\", alpha=0.4, color='xkcd:merlot', edgecolor= 'xkcd:merlot', \n",
    "                      linewidth = 1, data=data, hue = 'Shape')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title = '',fontsize='15')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n",
    "plt.plot([0, 10], [0, 10], linestyle='--', color = 'xkcd:apricot')\n",
    "ax.set_ylim(-0.1,2)\n",
    "ax.set_xlim(-0.1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks', {'grid.linestyle': '--'})\n",
    "\n",
    "colours = {'Convergent':'xkcd:mid blue', 'Divergent':'xkcd:pale pink'}\n",
    "x_axis = 'M8'\n",
    "y_axis = 'M4'\n",
    "g = sns.relplot(x=x_axis, y=y_axis,  palette = colours, hue = 'Shape',\n",
    "                 data=area_data, alpha = 0.7, legend = 'brief', edgecolor=\"k\", style = 'Shape')\n",
    "\n",
    "ax = g.axes[0,0]\n",
    "ax.set_xlim(-0.1,6)\n",
    "ax.set_ylim(-0.1,6)\n",
    "ax.set_xlabel(x_axis, fontsize = 20)\n",
    "ax.set_ylabel(y_axis, fontsize = 20)\n",
    "leg = g._legend\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
    "plt.plot([0, 10], [0, 10], linestyle='--', color = 'xkcd:chocolate', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_5m_divergent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'ticks')\n",
    "\n",
    "data = corr_5m_divergent\n",
    "\n",
    "mask = np.triu(np.ones_like(data, dtype=np.bool))\n",
    "\n",
    "comparison = sns.heatmap(data, xticklabels=data.columns, mask=mask,\n",
    "                         yticklabels=data.columns, annot = True,\n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True), vmin = 0.5, vmax = 1, linecolor = 'white', linewidths = 3)\n",
    "\n",
    "comparison.set_xticklabels(comparison.get_xticklabels(), rotation=45)\n",
    "comparison.set_yticklabels(comparison.get_yticklabels(), rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dict_convergent = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation_dict['D4/D8'] = [c.iloc[1,0], c_2m.iloc[1,0], c_3m.iloc[1,0], c_4m.iloc[1,0], c_5m.iloc[1,0]]\n",
    "#correlation_dict['D4/Dinf'] = [c.iloc[2,0], c_2m.iloc[2,0], c_3m.iloc[2,0], c_4m.iloc[2,0], c_5m.iloc[2,0]]\n",
    "#correlation_dict['D4/M4'] = [c.iloc[3,0], c_2m.iloc[3,0], c_3m.iloc[3,0], c_4m.iloc[3,0], c_5m.iloc[3,0]]\n",
    "correlation_dict_convergent['D4/M8'] = [corr_1m_convergent.iloc[4,0], \n",
    "                             corr_2m_convergent.iloc[4,0], corr_3m_convergent.iloc[4,0], \n",
    "                             corr_4m_convergent.iloc[4,0], corr_5m_convergent.iloc[4,0]]\n",
    "#correlation_dict['D8/Dinf'] = [c.iloc[2,1], c_2m.iloc[2,1], c_3m.iloc[2,1], c_4m.iloc[2,1], c_5m.iloc[2,1]]\n",
    "#correlation_dict['D8/M4'] = [c.iloc[3,1], c_2m.iloc[3,1], c_3m.iloc[3,1], c_4m.iloc[3,1], c_5m.iloc[3,1]]\n",
    "correlation_dict_convergent['D8/M8'] = [corr_1m_convergent.iloc[4,1], \n",
    "                             corr_2m_convergent.iloc[4,1], corr_3m_convergent.iloc[4,1], \n",
    "                             corr_4m_convergent.iloc[4,1], corr_5m_convergent.iloc[4,1]]\n",
    "#correlation_dict['Dinf/M4'] = [c.iloc[3,2], c_2m.iloc[3,2], c_3m.iloc[3,2], c_4m.iloc[3,2], c_5m.iloc[3,2]]\n",
    "correlation_dict_convergent['Dinf/M8'] = [corr_1m_convergent.iloc[4,2], \n",
    "                               corr_2m_convergent.iloc[4,2], corr_3m_convergent.iloc[4,2], \n",
    "                               corr_4m_convergent.iloc[4,2], corr_5m_convergent.iloc[4,2]]\n",
    "correlation_dict_convergent['M4/M8'] = [corr_1m_convergent.iloc[4,3], \n",
    "                             corr_2m_convergent.iloc[4,3], corr_3m_convergent.iloc[4,3], \n",
    "                             corr_4m_convergent.iloc[4,3], corr_5m_convergent.iloc[4,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " correlation_convergent_dataframe = pd.DataFrame.from_dict(correlation_dict_convergent, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_corr_1m =  correlation_convergent_dataframe.iloc[:,0].to_frame()\n",
    "convergent_corr_2m =  correlation_convergent_dataframe.iloc[:,1].to_frame()\n",
    "convergent_corr_3m =  correlation_convergent_dataframe.iloc[:,2].to_frame()\n",
    "convergent_corr_4m =  correlation_convergent_dataframe.iloc[:,3].to_frame()\n",
    "convergent_corr_5m =  correlation_convergent_dataframe.iloc[:,4].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_corr_1m_rename = convergent_corr_1m.rename(columns={0: \"Correlation\"})\n",
    "convergent_corr_2m_rename = convergent_corr_2m.rename(columns={1: \"Correlation\"})\n",
    "convergent_corr_3m_rename = convergent_corr_3m.rename(columns={2: \"Correlation\"})\n",
    "convergent_corr_4m_rename = convergent_corr_4m.rename(columns={3: \"Correlation\"})\n",
    "convergent_corr_5m_rename = convergent_corr_5m.rename(columns={4: \"Correlation\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_corr_1m_rename.insert(1, 'Resolution', True) \n",
    "convergent_corr_2m_rename.insert(1, 'Resolution', True) \n",
    "convergent_corr_3m_rename.insert(1, 'Resolution', True) \n",
    "convergent_corr_4m_rename.insert(1, 'Resolution', True) \n",
    "convergent_corr_5m_rename.insert(1, 'Resolution', True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_corr_1m_rename.insert(2, \"Method\", ['D4/M8', 'D8/M8', 'Dinf/M8','M4/M8'], True)  \n",
    "convergent_corr_2m_rename.insert(2, \"Method\", ['D4/M8', 'D8/M8', 'Dinf/M8','M4/M8'], True)  \n",
    "convergent_corr_3m_rename.insert(2, \"Method\", ['D4/M8', 'D8/M8', 'Dinf/M8','M4/M8'], True)  \n",
    "convergent_corr_4m_rename.insert(2, \"Method\", ['D4/M8', 'D8/M8', 'Dinf/M8','M4/M8'], True) \n",
    "convergent_corr_5m_rename.insert(2, \"Method\", ['D4/M8', 'D8/M8', 'Dinf/M8','M4/M8'], True)\n",
    "\n",
    "#corr_1m_rename.insert(2, \"Method\", ['D4/D8','D4/Dinf', 'D4/M4', \n",
    "#                                           'D4/M8', 'D8/Dinf', 'D8/M4', 'D8/M8', 'Dinf/M4', 'Dinf/M8','M4/M8'], True) \n",
    "#corr_2m_rename.insert(2, \"Method\", ['D4/D8','D4/Dinf', 'D4/M4', \n",
    "#                                           'D4/M8', 'D8/Dinf', 'D8/M4', 'D8/M8', 'Dinf/M4', 'Dinf/M8','M4/M8'], True) \n",
    "#corr_3m_rename.insert(2, \"Method\", ['D4/D8','D4/Dinf', 'D4/M4', \n",
    "#                                           'D4/M8', 'D8/Dinf', 'D8/M4', 'D8/M8', 'Dinf/M4', 'Dinf/M8','M4/M8'], True) \n",
    "#corr_4m_rename.insert(2, \"Method\", ['D4/D8','D4/Dinf', 'D4/M4', \n",
    "#                                           'D4/M8', 'D8/Dinf', 'D8/M4', 'D8/M8', 'Dinf/M4', 'Dinf/M8','M4/M8'], True) \n",
    "#corr_5m_rename.insert(2, \"Method\", ['D4/D8','D4/Dinf', 'D4/M4', \n",
    "#                                           'D4/M8', 'D8/Dinf', 'D8/M4', 'D8/M8', 'Dinf/M4', 'Dinf/M8','M4/M8'], True) \n",
    "\n",
    "\n",
    "convergent_corr_1m_rename['Resolution'] = '1m'\n",
    "convergent_corr_2m_rename['Resolution'] = '2m'\n",
    "convergent_corr_3m_rename['Resolution'] = '3m'\n",
    "convergent_corr_4m_rename['Resolution'] = '4m'\n",
    "convergent_corr_5m_rename['Resolution'] = '5m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_combined_correlations = convergent_corr_1m_rename.append([convergent_corr_2m_rename, \n",
    "                                                                   convergent_corr_3m_rename,\n",
    "                                                                   convergent_corr_4m_rename,\n",
    "                                                                   convergent_corr_5m_rename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent_combined_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'ticks')\n",
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "data = convergent_combined_correlations\n",
    "colours = {'D4/M8':'xkcd:burnt yellow', 'D8/M8':'xkcd:merlot', 'Dinf/M8':'xkcd:dark sea green', 'M4/M8':'xkcd:cobalt blue'}\n",
    "g = sns.stripplot(x = 'Resolution', y = 'Correlation', hue = 'Method',size=15, marker=\"o\",\n",
    "                   edgecolor=\"black\", alpha=.7, palette = colours,\n",
    "             data=data,  linewidth=1)\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "g.set(ylim = (0.6, 1))\n",
    "#for ind, label in enumerate(g.get_xticklabels()):\n",
    "#    if ind % 2 == 0:  # every 10th label is kept\n",
    "#        label.set_visible(False)\n",
    "#    else:\n",
    "#        label.set_visible(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Resolution', fontsize = 20)\n",
    "ax.set_ylabel('Correlation', fontsize = 20)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='22') # for legend title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'ticks')\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "jitter = 0.15\n",
    "data = convergent_combined_correlations\n",
    "ylim_min = .6\n",
    "ylim_max = 1\n",
    "#plt.clf()\n",
    "D4p = data[(data['Method']=='D4/M8')]\n",
    "colors = ['burnt yellow']\n",
    "m = sns.stripplot('Resolution','Correlation',hue='Method',\n",
    "                  marker='o',data=D4p, jitter=jitter, \n",
    "                  palette=sns.xkcd_palette(colors),\n",
    "                  split=True,linewidth=2,edgecolor=\"black\", size = 15, alpha = 0.7)\n",
    "m.set(ylim = (ylim_min, ylim_max))\n",
    "D8p = data[(data['Method']=='D8/M8')]\n",
    "colors = ['merlot']\n",
    "n = sns.stripplot('Resolution','Correlation',hue='Method',\n",
    "                  marker='v',data=D8p, jitter=jitter, \n",
    "                  palette=sns.xkcd_palette(colors),\n",
    "                  split=True,linewidth=2,edgecolor=\"black\", size = 15, alpha = 0.7)\n",
    "\n",
    "Dinfp = data[(data['Method']=='Dinf/M8')]\n",
    "colors = ['dark sea green']\n",
    "o = sns.stripplot('Resolution','Correlation',hue='Method',\n",
    "                  marker='s',data=Dinfp, jitter=jitter, \n",
    "                  palette=sns.xkcd_palette(colors),\n",
    "                  split=True,linewidth=2,edgecolor=\"black\", size = 15, alpha = 0.7)\n",
    "\n",
    "M4p = data[(data['Method']=='M4/M8')]\n",
    "colors = ['cobalt blue']\n",
    "p = sns.stripplot('Resolution','Correlation',hue='Method',\n",
    "                  marker='D',data=M4p, jitter=jitter, \n",
    "                  palette=sns.xkcd_palette(colors),\n",
    "                  split=True,linewidth=2,edgecolor=\"black\", size = 15, alpha = 0.7)\n",
    "\n",
    "plt.grid(linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "g.set(ylim = (ylim_min, ylim_max))\n",
    "ax.set_xlabel('Resolution', fontsize = 15)\n",
    "ax.set_ylabel('Correlation', fontsize = 15)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='22') # for legend title\n",
    "\n",
    "D4l = Line2D([], [], color='xkcd:burnt yellow', marker='o', linestyle='None',\n",
    "                          markersize=15, label='D4-M8')\n",
    "D8l = Line2D([], [], color='xkcd:merlot', marker='v', linestyle='None',\n",
    "                          markersize=15, label='D8-M8')\n",
    "Dinfl = Line2D([], [], color='xkcd:dark sea green', marker='s', linestyle='None',\n",
    "                          markersize=15, label='Dinf-M8')\n",
    "M4l = Line2D([], [], color='xkcd:cobalt blue', marker='D', linestyle='None',\n",
    "                          markersize=15, label='M4-M8')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_xlabel('Resolution', fontsize = 20)\n",
    "ax.set_ylabel('Correlation', fontsize = 20)\n",
    "\n",
    "plt.legend(handles=[D4l, D8l, Dinfl,M4l],fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = c_5m\n",
    "\n",
    "mask = np.triu(np.ones_like(data, dtype=np.bool))\n",
    "\n",
    "comparison = sns.heatmap(data, xticklabels=c.columns, mask=mask,\n",
    "                         yticklabels=c.columns, annot = True,\n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True), vmin = 0.8, vmax = 1, linecolor = 'white', linewidths = 3)\n",
    "\n",
    "comparison.set_xticklabels(comparison.get_xticklabels(), rotation=45)\n",
    "comparison.set_yticklabels(comparison.get_yticklabels(), rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isolate_catchment_area_nodes = np.isin(grid_nodes, catchment_area_node_list).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(isolate_catchment_area_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(isolate_catchment_area_nodes, cmap=\"terrain\");\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def np_array_to_Geotiff(newfile, original_tiff, np_array, dtype):\n",
    "    \n",
    "    cols = np_array.shape[1]\n",
    "    rows = np_array.shape[0]\n",
    "    originX, pixelWidth, b, originY, d, pixelHeight = original_tiff.GetGeoTransform() \n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    GDT_dtype = gdal.GDT_Unknown\n",
    "    if dtype == \"Float64\": \n",
    "        GDT_dtype = gdal.GDT_Float64\n",
    "    elif dtype == \"Float32\":\n",
    "        GDT_dtype = gdal.GDT_Float32\n",
    "    else:\n",
    "        print(\"Not supported data type.\")\n",
    "    \n",
    "    if np_array.ndim == 2:\n",
    "        band_num = 1\n",
    "    else:\n",
    "        band_num = np_array.shape[2]\n",
    "\n",
    "    outRaster = driver.Create(newfile, cols, rows, band_num, GDT_dtype)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    \n",
    "    # Loop over all bands.\n",
    "    for b in range(band_num):\n",
    "        outband = outRaster.GetRasterBand(b + 1)\n",
    "    \n",
    "        # Read in the band's data into the third dimension of our array\n",
    "        if band_num == 1:\n",
    "            outband.WriteArray(np_array)\n",
    "        else:\n",
    "            outband.WriteArray(np_array[:,:,b])\n",
    "\n",
    "    # setteing srs from input tif file.\n",
    "    prj=original_tiff.GetProjection()\n",
    "    outRasterSRS = osr.SpatialReference(wkt=prj)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    outRaster = None\n",
    "    \n",
    "    return outRaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array_to_Geotiff('divnode.tif', input_geotiff, outlet_ids, input_DEM.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
